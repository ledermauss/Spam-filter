---
title: "R Notebook"
output: pdf
---
# Threshold test
```{r}
library(ggplot2)
library(dplyr)
thresholds <- read.csv("../datasets/nbfh.threshold.csv")
thresholds$threshold <- as.factor(thresholds$threshold)
# predictions (file with tabs)
nbfh <- read_delim("../datasets/nbfh.threshold.pred",
     "\t", escape_double = FALSE, col_names = FALSE,
     trim_ws = TRUE)
names(nbfh) <- c("Label", "Predicted", "Spam_prob ")

# Suggestion: since under 0.5 there is almost no probability, I could remove
# the 0.25 threshold
# Also about this: this is mostly useless, better the ROC. No need of new 
# metric, just hte predicion values we currently have in "nbfh"
ggplot(thresholds, aes(samples, y=rec, col = threshold)) + geom_line() + 
  labs(y = "Recall")
ggplot(thresholds, aes(samples, y=prec, col = threshold)) + geom_line() + 
  labs(y = "Precission")
ggplot(thresholds, aes(samples, y=acc, col = threshold)) + geom_line() +
  labs(y = "Accuracy")

hist(nbfh$Spam_prob, main = "Spam prediction values", xlab = "Spam probability",
     breaks = seq(0,1,0.1))
# so far: we are gonna choose the threshold to be 0.75, because the precision is
# better

```

# NGrams size
Using the accumulated version of the codebase
```{r}
ngrams <- read.csv("../datasets/nbfh.ngrams.csv")
ngrams$ngrams <- as.factor(ngrams$ngrams)
ggplot(ngrams, aes(samples, acc, col = ngrams)) + geom_smooth() + 
  labs(y = "Accuracy")
ggplot(ngrams, aes(samples, acc, col = ngrams)) + geom_smooth() + 
  labs(y = "Precission")
ggplot(ngrams, aes(samples, acc, col = ngrams)) + geom_smooth() + 
  labs(y = "Recall")
ggplot(ngrams, aes(rec, prec, col = ngrams)) + geom_line() + 
  labs(title = "Precision-recall curve")
```
Conclussion: the best is using just one ngram

# Buckets size
X axis: memory usage
```{r}
buckets <- read.csv("../datasets/nbfh.buckets.csv")
buckets$memory <- 2^buckets$buckets
buckets <- buckets %>% group_by(buckets) %>% filter(samples == max(samples))
ggplot(buckets, aes(buckets, acc)) + geom_line() + 
  labs(title = "Accuracy curve")
# TODO: add labs to each point in the line and plot the other two metrics
```
Clearly, from 18 onwards is good (does not improve anymore)

# Perceptron
## Learning rate test
```{r}
lrate <- read.csv("../datasets/pfh.lrate.csv") %>% filter(lrate %% 0.2 != 0,
                                                          lrate != 0.1)

lrate$lrate <- as.factor(lrate$lrate)
# filter most: show only 0.1, 0.3, 0.5, 0.7, 0.9 and 0.01 and 0.001
ggplot(lrate, aes(samples, y=rec, col = lrate)) + geom_line() + 
  labs(y = "Recall")
ggplot(lrate, aes(samples, y=acc, col = lrate)) + geom_line() + 
  labs(y = "Accuracy")
ggplot(lrate, aes(samples, y=prec, col = lrate)) + geom_line() + 
  labs(y = "Precision")

```
Looks like 0.6 is good in this dataset


