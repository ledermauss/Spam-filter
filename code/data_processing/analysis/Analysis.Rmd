---
title: "R Notebook"
output: pdf
---
# Threshold test
```{r}
library(ggplot2)
thresholds <- read.csv("../datasets/nbfh.threshold.csv")
thresholds$threshold <- as.factor(thresholds$threshold)
# predictions (file with tabs)
nbfh <- read_delim("../datasets/nbfh.threshold.pred",
     "\t", escape_double = FALSE, col_names = FALSE,
     trim_ws = TRUE)
names(nbfh) <- c("Label", "Predicted", "Spam_prob ")

# Suggestion: since under 0.5 there is almost no probability, I could remove
# the 0.25 threshold
# Also about this: this is mostly useless, better the ROC. No need of new 
# metric, just hte predicion values we currently have in "nbfh"
ggplot(thresholds, aes(samples, y=rec, col = threshold)) + geom_line() + 
  labs(y = "Recall")
ggplot(thresholds, aes(samples, y=prec, col = threshold)) + geom_line() + 
  labs(y = "Precission")
ggplot(thresholds, aes(samples, y=acc, col = threshold)) + geom_line() +
  labs(y = "Accuracy")

hist(nbfh$Spam_prob, main = "Spam prediction values", xlab = "Spam probability",
     breaks = seq(0,1,0.1))
# so far: we are gonna choose the threshold to be 0.75, because the precision is
# better

```

# NGrams size
Using the accumulated version of the codebase
```{r}
ngrams <- read.csv("../datasets/nbfh.ngrams.csv")
ngrams$ngrams <- as.factor(ngrams$ngrams)
ggplot(ngrams, aes(samples, acc, col = ngrams)) + geom_line() + 
  labs(y = "Accuracy")
ggplot(ngrams, aes(samples, acc, col = ngrams)) + geom_line() + 
  labs(y = "Precission")
ggplot(ngrams, aes(samples, acc, col = ngrams)) + geom_line() + 
  labs(y = "Recall")
ggplot(ngrams, aes(rec, prec, col = ngrams)) + geom_smooth() + 
  labs(title = "Precision-recall curve")
```
Conclussion: the best is using just one ngram

# Buckets size
X axis: memory usage

